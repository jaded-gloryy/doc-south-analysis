{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An analysis of the influence of Black Southern Churches on the Southern Black Community\n",
    "\n",
    "## Background:\n",
    "\n",
    "Documenting the American South is one of the longest running digital publishing initiatives at the University of North Carolina. It was designed to give researchers digital access to some of the libraryâ€™s unique collections in the form of high quality page scans as well as structured, corrected and machine readable text. (https://docsouth.unc.edu/docsouthdata/)\n",
    "\n",
    "## Goal: \n",
    "\n",
    "Analyze rhetoric of the Black Southern Church in the American South and it's effects on documents written by self emancipated and previously enslaved Black people.\n",
    "\n",
    "## Research question:\n",
    "\n",
    "Are there any measurable similaries between the themes of documents from Southern Black churches and the documents from self-emancipated and freed Black people? \n",
    "\n",
    "## Approach:\n",
    "\n",
    "[Documenting The American South](https://docsouth.unc.edu/) is one of the longest running efforts by the University of North Carolina to collect, digitize, and publish documents from self-emancipated and freed Black people. Using [DocSouth Data](https://docsouth.unc.edu/docsouthdata/) and data from the [Religious Text Content Guide](https://docsouth.unc.edu/neh/religiouscontent.html), analyze the correlation between autobiographies, biographies, church documents, sermons, histories, encyclopedias, and other published materials from Southern Black churches and the narratives of slaves in regards to religion.\n",
    "\n",
    "Proposed analysis:\n",
    "\n",
    "- Evaluate language of both data sets\n",
    "- Evaluate themes of both data sets\n",
    "- Using data from the [Religious Text Content Guide](https://docsouth.unc.edu/neh/religiouscontent.html), develop a theme predictor for texts\n",
    "- Evaluate how much (if any) thematic overlap there is between religious texts and slave narratives\n",
    "\n",
    "## Repo contents:\n",
    "- [SouthernBlackChurchRhetoric](https://github.com/jaded-gloryy/doc-south-analysis/blob/main/SouthernBlackChurchRhetoric.ipynb) contains all analysis.\n",
    "- [Scrape_website](https://github.com/jaded-gloryy/doc-south-analysis/blob/main/scrape_website.py) contains the functions used to obtain [Religious Text Content Guide](https://docsouth.unc.edu/neh/religiouscontent.html) data.\n",
    "- [Utils](https://github.com/jaded-gloryy/doc-south-analysis/blob/main/utils.py) contains generic functions for parsing an html document.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get content guide data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was scraped from [religious text content guide data](https://docsouth.unc.edu/neh/religiouscontent.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data scraped from the web and turn it into a df\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "from scrape_website import scrape_data, custom_filter, build_dict\n",
    "url = \"https://docsouth.unc.edu/neh/religiouscontent.html\"\n",
    "tag_list = scrape_data(url=url, filter=custom_filter)\n",
    "data_dict = build_dict(tag_list=tag_list)\n",
    "content_guide_data = df.from_dict(data_dict)\n",
    "content_guide_data = content_guide_data.dropna(subset=\"page_link\")\n",
    "content_guide_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there's a typo in this table. Replace title with appropriate year\n",
    "non_num_yrs = content_guide_data[\"year\"].str.isnumeric() == False\n",
    "content_guide_data[non_num_yrs]\n",
    "\n",
    "change_dict = {\n",
    "        \"Offley, G. W. (Greensbury Washington\":\"1859\",\n",
    "        \"Latta, M. L. (Morgan London\":\"1903\",\n",
    "        \"Jamison, M. F. (Monroe Franklin\":\"1912\",\n",
    "        \"Brinch, Boyrereau and Prentiss, Benjamin F. (Benjamin Franklin\":\"1817\",\n",
    "        \"Foster, G. L. (Gustavus Lemuel\":\"1860\",\n",
    "        \"Bradford, Sarah H. (Sarah Hopkins\":\"1869\",\n",
    "        \"Green, J. D. (Jacob D.\":\"1864\",\n",
    "        \"E. M. W. (Elizabeth Merwin Wickham\":\"1869\"\n",
    "    }\n",
    "\n",
    "# replace years\n",
    "content_guide_data[\"year\"] = content_guide_data[\"year\"].replace(change_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace remaining non-numeric years\n",
    "# find years \"publ.?\" where title says \"Experience and Personal Narrative of Uncle Tom.\" and replace with \"1854\"\n",
    "publ_string = content_guide_data[\"year\"].str.contains(\"publ.?\")\n",
    "string_1854 = \"Experience and Personal Narrative of Uncle Tom\"\n",
    "find_1854 = content_guide_data[\"title\"].str.contains(string_1854)\n",
    "publ_1854 = content_guide_data[publ_string & find_1854]\n",
    "\n",
    "# update values that should say 1854\n",
    "content_guide_data[\"year\"].loc[publ_1854.index] = \"1854\"\n",
    "\n",
    "# find years \"publ.?\" where title says \"Sketch of the Life of Mr. Lewis Charlton\" and replace with \"1870\"\n",
    "string_1870 = \"Sketch of the Life of Mr. Lewis Charlton\"\n",
    "find_1870 = content_guide_data[\"title\"].str.contains(string_1870)\n",
    "publ_1870 = content_guide_data[publ_string & find_1870]\n",
    "\n",
    "# content_guide_data_updated = content_guide_data[publ_string & find_1870].replace(\"publ.?\",\"1870\")\n",
    "content_guide_data[\"year\"].loc[publ_1870.index] = \"1870\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get text files from links in page column\n",
    "from config import CONFIG\n",
    "content_guide_data.to_csv(CONFIG[\"CGD_FILEPATH\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get text data from the documents in the content guide"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The next 3 cells contain code to grab text from specific pages of each document in the content_guide_data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the code below is saved in thematic_text.txt. Since this only needs to be performed once, the code is commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get text files from links in page column\n",
    "# from scrape_website import combine_url,get_pages_from_url, get_page_list\n",
    "# base_url = \"https://docsouth.unc.edu\"\n",
    "# #replace roman numeral ranges and typo from website\n",
    "# content_guide_data = content_guide_data.replace({\"page_numbers\":{\"iv-viii\":\"iv,v,vi,vii,viii\", \"vi-viii\":\"vi,vii,viii\",\"28-19\":\"28-29\"}})\n",
    "# page_numbers = content_guide_data[\"page_numbers\"]\n",
    "# page_urls = content_guide_data[\"page_link\"]\n",
    "\n",
    "# full_links = combine_url(base_url=base_url, specific_url=list(page_urls))\n",
    "# page_num_list = list(page_numbers)\n",
    "\n",
    "# # get a list of pages\n",
    "# page_ranges = []\n",
    "# for page in page_num_list:\n",
    "#     page_ranges.append(get_page_list(page))\n",
    "# # manual page update for \n",
    "# page_ranges[374] = [\"9\",\"16\"]\n",
    "\n",
    "# thematic_texts = get_pages_from_url(urls=full_links, pages=page_ranges)\n",
    "\n",
    "# with open('thematic_text.txt', 'w') as f:\n",
    "#     for line in thematic_texts:\n",
    "#         f.write(line)\n",
    "#         f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # manual text update\n",
    "# thematic_texts[45] = \"\"\"\n",
    "\n",
    "# About Christmas, my master would give four or five days' holiday to his slaves; during which time, he supplied them plentifully with new whiskey, which kept them in a continual state of the most beastly intoxication. He often absolutely forced them to drink more, when they had told him they had had enough. He would then call them together, and say, \"Now, you slaves, don't you see what bad use you have been making of your liberty? Don't you think you had better have a master, to look after you, and make you work, and keep you from such a brutal state, which is a disgrace to you, and would ultimately be an injury to the community at large?\" Some of the slaves, in that whining, cringing manner, which is one of the baneful effects of slavery, would reply, \"Yees, Massa; if we go on in dis way, no good at all.\"\n",
    "\n",
    "#         Thus, by an artfully-contrived plan, the slaves themselves are made to put the seal upon their own servitude. The masters, by the system, are rendered as cunning and scheming as the slaves themselves.\n",
    "\n",
    "#         \"Joe,\" said a master, \"if you will work well for me, you shall be buried in my grave.\" The slave said nothing, in reply; but thought, Massa is a bad man, and that he would not like to be buried near him. The slave thought he had been too near his master, all his life, and had rather be away from him, when he died. Seeing the slave idling, \"Joe,\" shouted his master, \"have you forgotten what I promised you, if you work well?\" \"No, Massa, me bemember; but me don't want.\" \"What for, Joe?\" \"Because de debbil might some day come, and steal me away, in mistake for you, Massa.\" His master was silent on this subject ever afterwards.\n",
    "# \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the code below is saved in cleaned_thematic_text.txt. Since this only needs to be performed once, the code is commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # clean up and save output to a txt for future use\n",
    "# from scrape_website import clean_up_text\n",
    "# cleaned_thematic_texts = []\n",
    "# for text in thematic_texts:\n",
    "#     new_text = clean_up_text(text)\n",
    "#     cleaned_thematic_texts.append(new_text)\n",
    "\n",
    "# # save cleaned text to a txt file\n",
    "# with open('cleaned_thematic_text.txt', 'w') as f:\n",
    "#     for line in cleaned_thematic_texts:\n",
    "#         f.write(line)\n",
    "#         f.write(\"\\n\")\n",
    "# cleaned_thematic_texts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
